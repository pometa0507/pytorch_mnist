{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch MNIST手書き数字の分類 - 畳み込み層ネットワーク -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 畳み込み層（CNN）で構築したネットワークの実装を行い、MNIST分類を学習し推論します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モジュールインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUとCPUの自動判別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasetの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size = 40000\n",
      "val_dataset size = 20000\n"
     ]
    }
   ],
   "source": [
    "#データ前処理 transform を設定\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),                      # Tensor変換とshape変換 [H, W, C] -> [C, H, W]\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])    # 標準化 平均:0.5  標準偏差:0.5\n",
    "\n",
    "\n",
    "#訓練用(train + validation)のデータセット サイズ:(channel, height, width) = (1,28,28) 60000枚\n",
    "trainval_dataset = datasets.MNIST(root='./data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "\n",
    "#訓練用ータセットを train と val にshuffleして分割する\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [40000, 20000])\n",
    "\n",
    "print(\"train_dataset size = {}\".format(len(train_dataset)))\n",
    "print(\"val_dataset size = {}\".format(len(val_dataset)))\n",
    "\n",
    "#テスト(test)用のデータセット サイズ:(channel, height, width) = (1,28,28) 10000枚\n",
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                                        train=False, \n",
    "                                        download=True, \n",
    "                                        transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detaloaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練用 Dataloder\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=64,\n",
    "                                            shuffle=True)\n",
    "#検証用 Dataloder\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                            batch_size=64,\n",
    "                                            shuffle=False)\n",
    "\n",
    "#テスト用 Dataloder\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                            batch_size=64,\n",
    "                                            shuffle=False)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader, \"test\": test_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 動作の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imges size =  torch.Size([64, 1, 28, 28])\n",
      "labels size =  torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOy0lEQVR4nO3df+xddX3H8ecLfywTmQMKDBHFObSNS4bSkCzT2cWJLckC3aKRzQTjljIci5JsEVyIJGTE/cDFZBmmBCIaQc2kg8C0MrOtmi2GtmNYbVFk5YdUasUFGCQqfe+P76l8Ld977pf743tv+Twfyc2993zOuefdC6/vOfd8zjmfVBWSnv+OmnUBklaGYZcaYdilRhh2qRGGXWqEYZcaYdiPQEn2JvntZc5bSX5lxPWMvKzmj2HXiknyc0muS3J/kseT/FeSDbOuqxWGXSvphcCDwFuAlwGXA59LctoMa2qGYT/CJTkryX8m+d8k+5L8fZIXHzbbOUnuS3Igyd8kOWrR8u9NsjvJD5NsTfKqadVaVf9XVVdU1d6qOlhVtwH/A5w5rXXqGYb9yPc0cAmwCvh14K3A+w6bZyOwFngjcC7wXoAk5wEfAn4XOAH4CnDTclaa5B+6PzBLPe5e5mecBLwW+MZy5td44rnxR54ke4E/qqp/WaLtA8Bbqmpj976ADVX1xe79+4Dfq6q3JvkC8I9VdV3XdhTwBLCmqu7vlj29qu6dwr/hRcAXgO9U1YWT/nw9m1v2I1yS1ya5Lcn3kjwGXMXCVn6xBxe9vh94eff6VcDHDm2RgUeBAKdMueajgE8BPwIunua69AzDfuS7BtjDwhb4F1jYLc9h85y66PUrgYe71w8CF1bVLy56/HxV/cewlSb5eJInBjwG7pYnCXAdcBILexg/Xv4/VeMw7Ee+Y4DHgCeSrAYuWmKeP09ybJJTgfcDn+2mfxy4LMnrAZK8LMk7lrPSqvrjqnrpgMfrexa9BlgD/E5VPbXMf6MmwLAf+f4M+H3gceBangnyYrcAO4C7gNtZ2LJSVVuAvwI+0/0E2AVMrd+7O9J/IXAG8L1FewJ/MK116hkeoJMa4ZZdaoRhlxph2KVGGHapES9cyZV1Z2RJmqKqOvw8C2DMLXuS9UnuSXJvkkvH+SxJ0zVy11uSFwDfAt4GPATcCZxfVd/sWcYtuzRl09iynwXcW1X3VdWPgM+wcEWVpDk0TthP4WcvsHiIJS6gSLIpyfYk28dYl6QxjXOAbqldhWftplfVZmAzuBsvzdI4W/aH+NmrqV7BM1dTSZoz44T9TuD0JK/uboP0LuDWyZQladJG3o2vqp8kuRjYCrwAuL6qvL2QNKdW9Ko3f7NL0zeVk2okHTkMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9SIkcdnB0iyF3gceBr4SVWtnURRkiZvrLB3fquqDkzgcyRNkbvxUiPGDXsBX0qyI8mmpWZIsinJ9iTbx1yXpDGkqkZfOHl5VT2c5ETgDuBPq2pbz/yjr0zSslRVlpo+1pa9qh7unvcDW4Czxvk8SdMzctiTHJ3kmEOvgbOBXZMqTNJkjXM0/iRgS5JDn3NjVX1xIlU1ZuPGjb3tb37zm3vb9+zZM7Bt8+bNI9Wk55+Rw15V9wG/NsFaJE2RXW9SIwy71AjDLjXCsEuNMOxSI8Y6g+45r6zRM+jWr1/f23777bf3th91VP/f5IMHDw5s+8EPftC77IYNG3rbd+zY0duu+TOVM+gkHTkMu9QIwy41wrBLjTDsUiMMu9QIwy41YhI3nNQQq1ev7m0fdq5DXz/6sOWPP/743mWH9fFfdNFFve1btmzpbdf8cMsuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjvJ59BVx55ZW97WvWrOltH9bXfdlllw1se/e739277LB++O5W4QMNux5+69atve2aPK9nlxpn2KVGGHapEYZdaoRhlxph2KVGGHapEfazr4CXvOQlYy3/5JNPjrzsmWee2dt+9dVX97YPGy76+9//fm/7unXrBrb1DTWt0Y3cz57k+iT7k+xaNO24JHck+Xb3fOwki5U0ecvZjf8EcPiQJpcCX66q04Evd+8lzbGhYa+qbcCjh00+F7ihe30DcN6E65I0YaPeg+6kqtoHUFX7kpw4aMYkm4BNI65H0oRM/YaTVbUZ2AztHqCT5sGoXW+PJDkZoHveP7mSJE3DqGG/Fbige30BcMtkypE0LUP72ZPcBKwDVgGPAB8G/gn4HPBK4AHgHVV1+EG8pT7L3fg5M+ye9tu2bettH3Y9fN/48GvXru1d9oEHHuht19IG9bMP/c1eVecPaHrrWBVJWlGeLis1wrBLjTDsUiMMu9QIwy41wktc1evtb397b/uwIZ/7bkV91VVX9S57+eWX97Zrad5KWmqcYZcaYdilRhh2qRGGXWqEYZcaYdilRkz9TjU6sg0bcvmOO+7obe/rp1+1atVINWk0btmlRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqE/eway+7du3vbzz777BWqRMO4ZZcaYdilRhh2qRGGXWqEYZcaYdilRhh2qRHeN34FXHLJJb3tr3vd63rbv/rVr/a2D+vr7rNmzZre9o0bN/a2n3feeb3tO3fuHNi2YcOG3mUPHDjQ266ljXzf+CTXJ9mfZNeiaVck+W6Su7rHOZMsVtLkLWc3/hPA+iWm/11VndE9/nmyZUmatKFhr6ptwKMrUIukKRrnAN3FSe7udvOPHTRTkk1JtifZPsa6JI1p1LBfA7wGOAPYB1w9aMaq2lxVa6tq7YjrkjQBI4W9qh6pqqer6iBwLXDWZMuSNGkjhT3JyYvebgR2DZpX0nwY2s+e5CZgHbAKeAT4cPf+DKCAvcCFVbVv6Moa7Wd/+umne9uX8d9g5OXHWXYSy69bt25g27DzB7S01atXD2zbu3cvTz311JL/0YbevKKqzl9i8nXLL03SPPB0WakRhl1qhGGXGmHYpUYYdqkR3kp6Bdx444297cMuEz366KNHXvewrrNpL79t27aBbeN2+w27tLfv8t1hyw5b97DLkp988sne9j179gxsG3Zp75YtW0Za1i271AjDLjXCsEuNMOxSIwy71AjDLjXCsEuN8FbSc6DvkkWA9euXut/nM/r66Yf12Q7r45/mJbLTvrz2nnvuGdg2rJ/82muv7W3v6ycH2Lp161jLj2PkW0lLen4w7FIjDLvUCMMuNcKwS40w7FIjDLvUCPvZ1euEE07obR82pPM03Xzzzb3trQ75bD+71DjDLjXCsEuNMOxSIwy71AjDLjXCsEuNWM6QzacCnwR+CTgIbK6qjyU5DvgscBoLwza/s6p+OOSz7GeXpmxQP/tywn4ycHJV7UxyDLADOA94D/BoVX0kyaXAsVX1wSGfZdilKRv5pJqq2ldVO7vXjwO7gVOAc4EbutluYOEPgKQ59Zx+syc5DXgD8DXgpKraBwt/EIATJ12cpMlZ9lhvSV4KfB74QFU9ttwxwJJsAjaNVp6kSVnWhTBJXgTcBmytqo920+4B1lXVvu53/b9VVe9d/PzNLk3fyL/Zs7AJvw7YfSjonVuBC7rXFwC3jFukpOlZztH4NwFfAb7OQtcbwIdY+N3+OeCVwAPAO6rq0SGf5ZZdmrKRu94mybBL0+f17FLjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUiKFhT3Jqkn9NsjvJN5K8v5t+RZLvJrmre5wz/XIljWro+OxJTgZOrqqdSY4BdgDnAe8Enqiqv132yhyfXZq6QeOzv3AZC+4D9nWvH0+yGzhlsuVJmrbn9Js9yWnAG4CvdZMuTnJ3kuuTHDtgmU1JtifZPlalksYydDf+pzMmLwX+HfjLqro5yUnAAaCAK1nY1X/vkM9wN16askG78csKe5IXAbcBW6vqo0u0nwbcVlW/OuRzDLs0ZYPCvpyj8QGuA3YvDnp34O6QjcCucYuUND3LORr/JuArwNeBg93kDwHnA2ewsBu/F7iwO5jX91lu2aUpG2s3flIMuzR9I+/GS3p+MOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSI4becHLCDgD3L3q/qps2j+a1tnmtC6xtVJOs7VWDGlb0evZnrTzZXlVrZ1ZAj3mtbV7rAmsb1UrV5m681AjDLjVi1mHfPOP195nX2ua1LrC2Ua1IbTP9zS5p5cx6yy5phRh2qREzCXuS9UnuSXJvkktnUcMgSfYm+Xo3DPVMx6frxtDbn2TXomnHJbkjybe75yXH2JtRbXMxjHfPMOMz/e5mPfz5iv9mT/IC4FvA24CHgDuB86vqmytayABJ9gJrq2rmJ2Ak+U3gCeCTh4bWSvLXwKNV9ZHuD+WxVfXBOantCp7jMN5Tqm3QMOPvYYbf3SSHPx/FLLbsZwH3VtV9VfUj4DPAuTOoY+5V1Tbg0cMmnwvc0L2+gYX/WVbcgNrmQlXtq6qd3evHgUPDjM/0u+upa0XMIuynAA8uev8Q8zXeewFfSrIjyaZZF7OEkw4Ns9U9nzjjeg43dBjvlXTYMONz892NMvz5uGYR9qWGppmn/r/fqKo3AhuAP+l2V7U81wCvYWEMwH3A1bMsphtm/PPAB6rqsVnWstgSda3I9zaLsD8EnLro/SuAh2dQx5Kq6uHueT+whYWfHfPkkUMj6HbP+2dcz09V1SNV9XRVHQSuZYbfXTfM+OeBT1fVzd3kmX93S9W1Ut/bLMJ+J3B6klcneTHwLuDWGdTxLEmO7g6ckORo4GzmbyjqW4ELutcXALfMsJafMS/DeA8aZpwZf3czH/68qlb8AZzDwhH57wB/MYsaBtT1y8B/d49vzLo24CYWdut+zMIe0R8CxwNfBr7dPR83R7V9ioWhve9mIVgnz6i2N7Hw0/Bu4K7ucc6sv7ueulbke/N0WakRnkEnNcKwS40w7FIjDLvUCMMuNcKwS40w7FIj/h8LcR2zLv80SgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_iterator = iter(dataloaders_dict[\"train\"])  # イテレータに変換\n",
    "imges, labels = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "print(\"imges size = \", imges.size())\n",
    "print(\"labels size = \", labels.size())\n",
    "\n",
    "#試しに1枚 plot してみる\n",
    "plt.imshow(imges[0].numpy().reshape(28,28), cmap='gray')\n",
    "plt.title(\"label = {}\".format(labels[0].numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワークモデルの作成\n",
    "- 畳み込み層CNNのモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)              # (Batch,  1, 28, 28) -> (Batch, 32, 26, 26)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)              # (Batch, 32, 26, 26) -> (Batch, 64, 24, 24)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)         # (Batch, 64, 24, 24) -> (Batch, 64, 12, 12)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)        # (Batch, 64, 12, 12) -> (Batch, 9216)\n",
    "        x = self.fc1(x)                # (Batch, 9216) -> (Batch, 128)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)                # (Batch, 128) -> (Batch, 10)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデル作成\n",
    "net = Net().to(device)   # GPUを使用する場合のために明示的に .to(device) を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#ネットワークのレイヤー確認\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 損失関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.CrossEntropyLoss() はソフトマックス関数＋クロスエントロピー誤差\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化手法の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習・検証の実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, device, num_epochs):\n",
    "    \n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epochごとの学習と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for i , (inputs, labels) in tqdm(enumerate(dataloaders_dict[phase])):\n",
    "                \n",
    "                # GPUを使用する場合は明示的に指定\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):  # 訓練モードのみ勾配を算出\n",
    "                    outputs = net(inputs)              # 順伝播\n",
    "                    loss = criterion(outputs, labels)  # 損失を計算\n",
    "                    _, preds = torch.max(outputs, 1)   # ラベルを予測\n",
    "                    \n",
    "  \n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # イタレーション結果の計算\n",
    "                    # lossの合計を更新\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  \n",
    "                    # 正解数の合計を更新\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # epochごとのlossと正解率を表示\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [00:26, 11.77it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.3020 Acc: 0.0985\n",
      "Epoch 2/3\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [04:11,  2.49it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2829 Acc: 0.9150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [00:28, 10.85it/s]\n",
      "1it [00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0735 Acc: 0.9783\n",
      "Epoch 3/3\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [02:07,  4.90it/s]\n",
      "1it [00:00,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1100 Acc: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [00:30, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0532 Acc: 0.9828\n"
     ]
    }
   ],
   "source": [
    "# 学習・検証を実行する\n",
    "num_epochs = 3\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストデータに対する予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASjUlEQVR4nO3dfbBU9X3H8fcnSKIVo4CiiDwYo6nWcVDRmBEdjIkh2AwaNZFMUtpGr51RU2cso2PjoK3tMObByHTGDD5UNEakEh9rLIhG6qiJaFQg+ACWAIKABRWsCsi3f5yDWa+7Z+/dZ+7v85rZubvnu+fsd8+9n3ue9uxRRGBmfd+n2t2AmbWGw26WCIfdLBEOu1kiHHazRDjsZolw2LuR9BtJ57V6XGs8SW9IGpvfv1rSv7W7p3bqs2GXtELSV9rdRzmSfi5pS37bKmlbyeNft6GfWZJ+WMN4nynpe+dth6Qf9eJ1P8jH2yjpYUmH9v4dVBcRUyPioh721PJ50Qp9NuydLCL+LiIGRMQA4F+Bu3Y+joiv93Z6kvo1vsvqIuKDkr4HAAcBHwD/0YvJ/HM+7ghgM3BjuSdJ2q3uhpuoQfOiqZILu6SBkh6UtEHSpvz+Qd2edoik30l6W9J9kgaVjH+CpCclvSXpBUnjmtDjbpLmSFqXv85jkr5QUp8labqkuZLeBb4kaYikX0t6R9LTkqZJeqRknCMlPZq/56WSzsiH/wA4C7gyXxrV88f5bWBFRPyutyNGxBZgFnBk3tc0Sb+UdJekzcC5kvpJulLSa5LelHSHpH1K3uP3Ja3Mf7dTSqefT++mksfj8vn0dj7OdzplXjRLcmEne8//DowkW5q8B3Tflvsr4G+BA4HtwHQAScOA/wSuAQYB/wDMkbRf9xeRNCIP6oga+7wfOAQ4AHgJmNmt/l3gSmAv4BlgBrAB2B/oAiaX9PJZYB5wM7Bv/v5ukfT5iJgOzCFfwkbEOfk48/L+y93urtDz5DJ99kje4yTg9yWDz8qnt3fe4xTgNGAs2ZJzG3BdPv5o4GdkITsIGJW/13Kv9XngQeBHwGDgWGBJp8yLpomIPnkDVgBf6cHzRgObSh7/BphW8vgIYCvQD7gMuL3b+P8FTC4Z97xe9nkV8IsqzzkA2AHsnj+eBcwoqe+e10eWDPsx8Eh+fzIwr9s0ZwKXlUzvh3XO70PJ/jEO68U4s8j+2b4FrAXu2fkegGnA3G7P/x/gxJLHBwP/B4hsc+jWktre+TwZWzK9m/L7VwN3FvTU8nnRiltHbwc1g6Q/I1sajAcG5oP3ktQvIj7MH68qGeWPQH+ypcRI4BxJ3yip9wcea3CPu5H9cX4zf90dZH/Qg4HXy/R4QF5fXTJsFdk/MvK+T5b0Vkl9N2BTA9ueDMyPiNerPvPj/iUirqlQ++g9ShIwHHhIUunZW58imy8Hlj4/It6W9HaF6Q4Hlveyz96odV40VYqr8ZcCXwC+GBGfBU7Oh6vkOcNL7o8gW118k+yP6faI2KfktmdETGtwj39Dtrp6CtkS6s/L9Fj6B/9G/nhYhfewimwpWdr3gIi4pMy0shfKtu+7713eebun23MFfI/Gr7Z+1Fdki8zXgS93ex+7R8SbZGsGH71nSXuTzbtyVpFtIhW+Zsm0OmFe1K2vh72/pN1LbruRbeO+B7yV73ibWma870o6Il8L+Cfg7nyp/wvgG5K+lu8s2j3f0dN9B1+99gLeB/4X2JNsH0FFEfE+8ABwdd7TkcB3Sp5yL3C0pG9L6i/p0/mOxsPy+jrgc92m+eUo2bvc7XZmtxZOAfYhWw3/SN5LSDqhd2+/op8D0yQNz6c/pGQtazbwTUlflPQZsnm2o8J0bgP+UtKZ+e9xP0lH5bWmzItO0NfD/hBZsHferiLbibMH2ZL6aeDhMuPdDtxKtsTcHfgBQESsAiYCV5DtDFtFttPoE/Mx30G3pcYddDfn038DWAQ80YNxLiBbld0A3ATcSXboh4jYBHyNbI1hLbCGLAz983FnAMflO5xm1dDvZGB2RLzXbfhwsu3xP9QwzXKuBR4BHs330D8JHAMQEb8nW2u7m2xzZiXZ7/gTImI5f/o9bgIWAn+Rl5s1L9pO+Q4F62MkXU+2Q++CNvZwHtlOqqvb1YP9icPeR+Sr7kG2FP0S2SHCSRFRbs3FEpTc3vg+bG+yzY8DyFb/r3HQrZSX7GaJ6Os76Mws19LV+G4fhjCzJogIlRte15Jd0nhJL0taJunyeqZlZs1V8za7stMqXwG+SnZc8xmyvb8Vj6l6yW7WfM1Ysh8PLIuI1yJiK9kJBBPrmJ6ZNVE9YR/Gx0/GWM3HP5sNgKQuSQslLazjtcysTvXsoCu3qvCJ1fSImEH2EUSvxpu1UT1L9tV8/Myqg8g+c21mHaiesD8DHCrpYEmfBs4l+3YVM+tANa/GR8R2SReRfVNLP+CWiFjSsM7MrKFa+nFZb7ObNV9TPlRjZrsOh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRJR8/XZASStADYDHwLbI2JMI5oys8arK+y5UyLizQZMx8yayKvxZomoN+wBzJX0rKSuck+Q1CVpoaSFdb6WmdVBEVH7yNKBEbFG0hBgHnBxRCwoeH7tL2ZmPRIRKje8riV7RKzJf64H7gGOr2d6ZtY8NYdd0p6S9tp5HzgNWNyoxsysserZG78/cI+kndP5ZUQ83JCuzKzh6tpm7/WLeZvdrOmass1uZrsOh90sEQ67WSIcdrNEOOxmiWjEiTBJOPvssyvWzj///MJx16xZU1h///33C+t33HFHYf2NN96oWFu2bFnhuJYOL9nNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0T4rLceeu211yrWRo0a1bpGyti8eXPF2pIlS1rYSWdZvXp1xdq1115bOO7Chbvut6j5rDezxDnsZolw2M0S4bCbJcJhN0uEw26WCIfdLBE+n72His5ZP+qoowrHXbp0aWH98MMPL6wfc8wxhfVx48ZVrJ1wwgmF465ataqwPnz48MJ6PbZv315Y37BhQ2F96NChNb/2ypUrC+u78nH2SrxkN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4fPZ+4CBAwdWrI0ePbpw3Geffbawftxxx9XUU09U+778V155pbBe7fMLgwYNqli78MILC8e94YYbCuudrObz2SXdImm9pMUlwwZJmifp1fxn5b82M+sIPVmNvxUY323Y5cD8iDgUmJ8/NrMOVjXsEbEA2Nht8ERgZn5/JnBGg/syswar9bPx+0fEWoCIWCtpSKUnSuoCump8HTNrkKafCBMRM4AZ4B10Zu1U66G3dZKGAuQ/1zeuJTNrhlrDfj8wOb8/GbivMe2YWbNUPc4u6U5gHLAvsA6YCtwLzAZGACuBcyKi+068ctPyarz12FlnnVVYnz17dmF98eLFFWunnHJK4bgbN1b9c+5YlY6zV91mj4hJFUqn1tWRmbWUPy5rlgiH3SwRDrtZIhx2s0Q47GaJ8Cmu1jZDhlT8lDUAixYtqmv8s88+u2Jtzpw5hePuynzJZrPEOexmiXDYzRLhsJslwmE3S4TDbpYIh90sEb5ks7VNta9z3m+//QrrmzZtKqy//PLLve6pL/OS3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhM9nt6Y68cQTK9YeffTRwnH79+9fWB83blxhfcGCBYX1vsrns5slzmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmifD57NZUEyZMqFirdhx9/vz5hfWnnnqqpp5SVXXJLukWSeslLS4ZdpWk1yU9n98q/0bNrCP0ZDX+VmB8meHXRcTo/PZQY9sys0arGvaIWABsbEEvZtZE9eygu0jSi/lq/sBKT5LUJWmhpIV1vJaZ1anWsN8AHAKMBtYCP6n0xIiYERFjImJMja9lZg1QU9gjYl1EfBgRO4AbgeMb25aZNVpNYZc0tOThmcDiSs81s85Q9Ti7pDuBccC+klYDU4FxkkYDAawALmhij9bB9thjj8L6+PHlDuRktm7dWjju1KlTC+vbtm0rrNvHVQ17REwqM/jmJvRiZk3kj8uaJcJhN0uEw26WCIfdLBEOu1kifIqr1WXKlCmF9aOPPrpi7eGHHy4c98knn6ypJyvPS3azRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBG+ZLMVOv300wvr9957b2H93XffrVgrOv0V4Omnny6sW3m+ZLNZ4hx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgifz564wYMHF9anT59eWO/Xr19h/aGHKl/z08fRW8tLdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEVXPZ5c0HLgNOADYAcyIiOslDQLuAkaRXbb5WxGxqcq0fD57i1U7Dl7tWPexxx5bWF++fHlhveic9WrjWm3qOZ99O3BpRBwOnABcKOkI4HJgfkQcCszPH5tZh6oa9ohYGxHP5fc3A0uBYcBEYGb+tJnAGc1q0szq16ttdkmjgKOB3wL7R8RayP4hAEMa3ZyZNU6PPxsvaQAwB7gkIt6Rym4WlBuvC+iqrT0za5QeLdkl9ScL+h0R8at88DpJQ/P6UGB9uXEjYkZEjImIMY1o2MxqUzXsyhbhNwNLI+KnJaX7gcn5/cnAfY1vz8wapSeH3sYC/w0sIjv0BnAF2Xb7bGAEsBI4JyI2VpmWD7212GGHHVZYf+mll+qa/sSJEwvrDzzwQF3Tt96rdOit6jZ7RDwBVNpAP7WepsysdfwJOrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIf5V0HzBy5MiKtblz59Y17SlTphTWH3zwwbqmb63jJbtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulggfZ+8Duroqf+vXiBEj6pr2448/Xliv9n0I1jm8ZDdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuHj7LuAsWPHFtYvvvjiFnViuzIv2c0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRFQ9zi5pOHAbcADZ9dlnRMT1kq4Czgc25E+9IiIealajKTvppJMK6wMGDKh52suXLy+sb9mypeZpW2fpyYdqtgOXRsRzkvYCnpU0L69dFxE/bl57ZtYoVcMeEWuBtfn9zZKWAsOa3ZiZNVavttkljQKOBn6bD7pI0ouSbpE0sMI4XZIWSlpYV6dmVpceh13SAGAOcElEvAPcABwCjCZb8v+k3HgRMSMixkTEmAb0a2Y16lHYJfUnC/odEfErgIhYFxEfRsQO4Ebg+Oa1aWb1qhp2SQJuBpZGxE9Lhg8tedqZwOLGt2dmjdKTvfEnAt8DFkl6Ph92BTBJ0mgggBXABU3p0OrywgsvFNZPPfXUwvrGjRsb2Y61UU/2xj8BqEzJx9TNdiH+BJ1ZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhFp5yV1Jvr6vWZNFRLlD5V6ym6XCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJaPUlm98E/ljyeN98WCfq1N46tS9wb7VqZG8jKxVa+qGaT7y4tLBTv5uuU3vr1L7AvdWqVb15Nd4sEQ67WSLaHfYZbX79Ip3aW6f2Be6tVi3pra3b7GbWOu1esptZizjsZoloS9gljZf0sqRlki5vRw+VSFohaZGk59t9fbr8GnrrJS0uGTZI0jxJr+Y/y15jr029XSXp9XzePS9pQpt6Gy7pMUlLJS2R9Pf58LbOu4K+WjLfWr7NLqkf8ArwVWA18AwwKSL+0NJGKpC0AhgTEW3/AIakk4EtwG0RcWQ+7FpgY0RMy/9RDoyIyzqkt6uALe2+jHd+taKhpZcZB84A/po2zruCvr5FC+ZbO5bsxwPLIuK1iNgKzAImtqGPjhcRC4Dul2SZCMzM788k+2NpuQq9dYSIWBsRz+X3NwM7LzPe1nlX0FdLtCPsw4BVJY9X01nXew9grqRnJXW1u5ky9o+ItZD98QBD2txPd1Uv491K3S4z3jHzrpbLn9erHWEv9/1YnXT878SIOAb4OnBhvrpqPdOjy3i3SpnLjHeEWi9/Xq92hH01MLzk8UHAmjb0UVZErMl/rgfuofMuRb1u5xV085/r29zPRzrpMt7lLjNOB8y7dl7+vB1hfwY4VNLBkj4NnAvc34Y+PkHSnvmOEyTtCZxG512K+n5gcn5/MnBfG3v5mE65jHely4zT5nnX9sufR0TLb8AEsj3yy4F/bEcPFfr6HPBCflvS7t6AO8lW67aRrRF9HxgMzAdezX8O6qDebgcWAS+SBWtom3obS7Zp+CLwfH6b0O55V9BXS+abPy5rlgh/gs4sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S8T/AzzvhOkEgmGIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_iterator = iter(dataloaders_dict[\"test\"])  # イテレータに変換\n",
    "imges, labels = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "\n",
    "net.eval() #推論モード\n",
    "with torch.set_grad_enabled(False):   # 推論モードでは勾配を算出しない\n",
    "    outputs = net(imges)               # 順伝播\n",
    "    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "    \n",
    "#テストデータの予測結果を描画\n",
    "plt.imshow(imges[0].numpy().reshape(28,28), cmap='gray')\n",
    "plt.title(\"Label: Target={}, Predict={}\".format(labels[0], preds[0].numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
