{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch MNIST手書き数字の分類 - RNNネットワーク -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RNNで構築したネットワークの実装を行い、MNIST分類を学習し推論します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 事前準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モジュールインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUとCPUの自動判別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasetの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size = 40000\n",
      "val_dataset size = 20000\n"
     ]
    }
   ],
   "source": [
    "#データ前処理 transform を設定\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),                      # Tensor変換とshape変換 [H, W, C] -> [C, H, W]\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])    # 標準化 平均:0.5  標準偏差:0.5\n",
    "\n",
    "\n",
    "#訓練用(train + validation)のデータセット サイズ:(channel, height, width) = (1,28,28) 60000枚\n",
    "trainval_dataset = datasets.MNIST(root='./data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "\n",
    "#訓練用ータセットを train と val にshuffleして分割する\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [40000, 20000])\n",
    "\n",
    "print(\"train_dataset size = {}\".format(len(train_dataset)))\n",
    "print(\"val_dataset size = {}\".format(len(val_dataset)))\n",
    "\n",
    "#テスト(test)用のデータセット サイズ:(channel, height, width) = (1,28,28) 10000枚\n",
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                                        train=False, \n",
    "                                        download=True, \n",
    "                                        transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detaloaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練用 Dataloder\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=64,\n",
    "                                            shuffle=True)\n",
    "#検証用 Dataloder\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                            batch_size=64,\n",
    "                                            shuffle=False)\n",
    "\n",
    "#テスト用 Dataloder\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                            batch_size=64,\n",
    "                                            shuffle=False)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader, \"test\": test_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 動作の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imges size =  torch.Size([64, 1, 28, 28])\n",
      "labels size =  torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOk0lEQVR4nO3dbawc5XnG8esCHCgYiqmLcRwbp4lLQyphB2NoKS0RTQR8AdoSxZWSU4XqQB0qu0qrUvohfEAVfUmiqBVERkYxVYoJNQjThtjUsoRNq4CNjDF2HVy/cWzXFoL6RQIB9t0PZ5wcDruzy+7szh7u/09a7ew8Mzu3V77OM7vz8jgiBOCj77S6CwDQH4QdSIKwA0kQdiAJwg4kQdiBJAj7BGR7j+3fbXPZsP3pDrfT8boYPIQdfWX7+LjHCdv/WHddGZxRdwHIJSImn5q2fY6kQ5Ieq6+iPOjZJzjbC2z/l+3/s33Q9j/Z/ti4xW60vcv267b/3vZpY9b/mu3ttt+0vdr2xX0s/w8kHZa0vo/bTIuwT3wnJP2ZpKmSfkPSdZIWjVvmFknzJX1O0k2SviZJtm+WdLek35P0yxoN3SPtbNT2/cUfmEaPLW3WPiTp4eCc7b4wn/PEY3uPpD+OiP9o0LZE0u9ExC3F65B0Q0T8uHi9SNLvR8R1tp+W9K8RsaxoO03ScUmfiYi9xbpzImJnD/4NsyTtlvTpiNhd9fvjg+jZJzjbv2r732z/r+2jkv5Go738WK+Nmd4r6ePF9MWSvnuqR5b0hiRLmtHruiV9VdIGgt4/hH3ie0DSf2u0Bz5Po7vlHrfMzDHTsyQdKKZfk3R7RJw/5vELEfGfrTZq+3sNflk/9Xiljbq/Kml5G8uhIoR94jtX0lFJx23/mqQ/abDMX9ieYnumpMWSHi3mf0/SX9n+rCTZ/kXbt7az0Yi4IyImN3l8tmxd27+p0b0HfoXvI8I+8f25pD+UdEzSg/p5kMd6UtImSZsl/bukZZIUEU9I+ltJK4qvAFsl3dCHmockPR4Rx/qwLRT4gQ5Igp4dSIKwA0kQdiAJwg4k0dcLYYozsgD0UESMP89CUpc9u+3rbe+wvdP2Xd28F4De6vjQm+3TJf1U0hckjUh6QdLCiNhWsg49O9BjvejZF0jaGRG7IuIdSSs0ekUVgAHUTdhn6P0XWIyowQUUtodtb7S9sYttAehSNz/QNdpV+MBuekQslbRUYjceqFM3PfuI3n811Sf086upAAyYbsL+gqQ5tj9Z3Abpy5JWVVMWgKp1vBsfEe/ZvlPSakmnS3ooItq5jhlADfp61Rvf2YHe68lJNQAmDsIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEh2Pzy5JtvdIOibphKT3ImJ+FUUBqF5XYS98PiJer+B9APQQu/FAEt2GPSStsb3J9nCjBWwP295oe2OX2wLQBUdE5yvbH4+IA7YvlPSMpD+NiGdLlu98YwDaEhFuNL+rnj0iDhTPhyU9IWlBN+8HoHc6Drvtc2yfe2pa0hclba2qMADV6ubX+GmSnrB96n3+JSJ+XElVACrX1Xf2D70xvrMDPdeT7+wAJg7CDiRB2IEkCDuQBGEHkqjiQhh06fzzzy9tX7duXWn7888/37Tt6aefLl33jDPK/wts2LChtP2tt94qbT9y5EjTtvPOO6903Wuuuaa0/eyzzy5tf+yxx0rbs6FnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkuOptAMyePbu0fdu2baXtZ555ZoXVfDivv15+r9Hdu3c3bZs1a1bputOmTStt37FjR2n7pZdeWtr+UcVVb0ByhB1IgrADSRB2IAnCDiRB2IEkCDuQBNezD4A9e/aUti9btqy0fdGiRU3b9u3bV7puq2PVrcybN6+0/Yorrujq/cusWLGiZ+/9UUTPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJx9Amh1b/Yyd9xxR2n76tWrO35vSZo0aVJp++WXX9607bnnnitdd+3ataXt9957b2k73q9lz277IduHbW8dM+8C28/YfrV4ntLbMgF0q53d+O9Lun7cvLskrY2IOZLWFq8BDLCWYY+IZyW9MW72TZKWF9PLJd1ccV0AKtbpd/ZpEXFQkiLioO0Lmy1oe1jScIfbAVCRnv9AFxFLJS2VuOEkUKdOD70dsj1dkornw9WVBKAXOg37KklDxfSQpCerKQdAr7Tcjbf9iKRrJU21PSLpm5Luk/RD27dJ2ifp1l4Wmd3kyZNL2995552mbWVjt1fh3XffLW0fHu7855qVK1eWtp88ebLj986oZdgjYmGTpusqrgVAD3G6LJAEYQeSIOxAEoQdSIKwA0kwZPMEsH79+tL2Xbt2NW0bGhpq2laFqVOnlrbv3bu3aVur21xfddVVpe1Hjhwpbc+KIZuB5Ag7kARhB5Ig7EAShB1IgrADSRB2IAluJT0BLFmypLT9zTff7FMlH3TllVeWtp911llN28rOD5A4jl41enYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILj7BPApk2b6i6hqcWLF3e87v33319hJWiFnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuC+8ehKq2GTd+zY0bTtsssuK123bChqNNfxfeNtP2T7sO2tY+bdY3u/7c3F48YqiwVQvXZ2478v6foG878TEXOLx4+qLQtA1VqGPSKelfRGH2oB0EPd/EB3p+0txW7+lGYL2R62vdH2xi62BaBLnYb9AUmfkjRX0kFJ32q2YEQsjYj5ETG/w20BqEBHYY+IQxFxIiJOSnpQ0oJqywJQtY7Cbnv6mJe3SNrabFkAg6Hl9ey2H5F0raSptkckfVPStbbnSgpJeyTd3sMaUaOLLrqoq/Xffvvtpm0cR++vlmGPiIUNZi/rQS0AeojTZYEkCDuQBGEHkiDsQBKEHUiCW0mj1IIF5edL2Q2vpvyZp556qspy0AV6diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IguPsKDVnzpzS9la3It+wYUOV5aAL9OxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATH2VHqkksuKW0/evRoaftLL71UZTnoAj07kARhB5Ig7EAShB1IgrADSRB2IAnCDiThVtcj254p6WFJF0k6KWlpRHzX9gWSHpU0W6PDNn8pIt5s8V7lG8PA2b9/f2n7iRMnSttnzZpVZTloQ0Q0vJl/Oz37e5K+ERGfkXSVpK/bvlTSXZLWRsQcSWuL1wAGVMuwR8TBiHixmD4mabukGZJukrS8WGy5pJt7VSSA7n2o7+y2Z0uaJ+knkqZFxEFp9A+CpAurLg5Addo+N972ZEkrJS2JiKOtxvgas96wpOHOygNQlbZ6dtuTNBr0H0TE48XsQ7anF+3TJR1utG5ELI2I+RExv4qCAXSmZdg92oUvk7Q9Ir49pmmVpKFiekjSk9WXB6Aq7ezGXy3pK5Jetr25mHe3pPsk/dD2bZL2Sbq1NyWil6ZPn17aPnny5NL2Rx99tMpy0EMtwx4RGyQ1+4J+XbXlAOgVzqADkiDsQBKEHUiCsANJEHYgCcIOJMGtpJObO3duaXur4+zr1q2rshz0ED07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBcfbkFi1a1NX669evr6gS9Bo9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXH25GbOnNnV+iMjIxVVgl6jZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJFqG3fZM2+tsb7f9iu3Fxfx7bO+3vbl43Nj7cgF0qp2Tat6T9I2IeNH2uZI22X6maPtORPxD78oDUJWWYY+Ig5IOFtPHbG+XNKPXhQGo1of6zm57tqR5kn5SzLrT9hbbD9me0mSdYdsbbW/sqlIAXWk77LYnS1opaUlEHJX0gKRPSZqr0Z7/W43Wi4ilETE/IuZXUC+ADrUVdtuTNBr0H0TE45IUEYci4kREnJT0oKQFvSsTQLfa+TXekpZJ2h4R3x4zf/qYxW6RtLX68gBUpZ1f46+W9BVJL9veXMy7W9JC23MlhaQ9km7vSYWo1Zo1a+ouARVp59f4DZLcoOlH1ZcDoFc4gw5IgrADSRB2IAnCDiRB2IEkCDuQhCOifxuz+7cxIKmIaHSonJ4dyIKwA0kQdiAJwg4kQdiBJAg7kARhB5Lo95DNr0vaO+b11GLeIBrU2ga1LonaOlVlbRc3a+jrSTUf2Li9cVDvTTeotQ1qXRK1dapftbEbDyRB2IEk6g770pq3X2ZQaxvUuiRq61Rfaqv1OzuA/qm7ZwfQJ4QdSKKWsNu+3vYO2ztt31VHDc3Y3mP75WIY6lrHpyvG0Dtse+uYeRfYfsb2q8VzwzH2aqptIIbxLhlmvNbPru7hz/v+nd326ZJ+KukLkkYkvSBpYURs62shTdjeI2l+RNR+Aobt35Z0XNLDEfHrxby/k/RGRNxX/KGcEhF/OSC13SPpeN3DeBejFU0fO8y4pJsl/ZFq/OxK6vqS+vC51dGzL5C0MyJ2RcQ7klZIuqmGOgZeRDwr6Y1xs2+StLyYXq7R/yx916S2gRARByPixWL6mKRTw4zX+tmV1NUXdYR9hqTXxrwe0WCN9x6S1tjeZHu47mIamBYRB6XR/zySLqy5nvFaDuPdT+OGGR+Yz66T4c+7VUfYG90fa5CO/10dEZ+TdIOkrxe7q2hPW8N490uDYcYHQqfDn3erjrCPSJo55vUnJB2ooY6GIuJA8XxY0hMavKGoD50aQbd4PlxzPT8zSMN4NxpmXAPw2dU5/HkdYX9B0hzbn7T9MUlflrSqhjo+wPY5xQ8nsn2OpC9q8IaiXiVpqJgekvRkjbW8z6AM491smHHV/NnVPvx5RPT9IelGjf4i/z+S/rqOGprU9SuSXioer9Rdm6RHNLpb965G94huk/RLktZKerV4vmCAavtnSS9L2qLRYE2vqbbf0uhXwy2SNhePG+v+7Erq6svnxumyQBKcQQckQdiBJAg7kARhB5Ig7EAShB1IgrADSfw/qnKiWMSWlhoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_iterator = iter(dataloaders_dict[\"train\"])  # イテレータに変換\n",
    "imges, labels = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "print(\"imges size = \", imges.size())\n",
    "print(\"labels size = \", labels.size())\n",
    "\n",
    "#試しに1枚 plot してみる\n",
    "plt.imshow(imges[0].numpy().reshape(28,28), cmap='gray')\n",
    "plt.title(\"label = {}\".format(labels[0].numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワークモデルの作成\n",
    "- RNNのモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.seq_len = 28              # 画像の Height を時系列のSequenceとしてRNNに入力する\n",
    "        self.feature_size = 28         # 画像の Width を特徴量の次元としてRNNに入力する\n",
    "        self.hidden_layer_size = 128   # 隠れ層のサイズ\n",
    "        self.rnn_layers = 1            # RNNのレイヤー数　(RNNを何層重ねるか)\n",
    "        \n",
    "        self.simple_rnn = nn.RNN(input_size = self.feature_size,\n",
    "                                 hidden_size = self.hidden_layer_size,\n",
    "                                 num_layers = self.rnn_layers) \n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_layer_size, 10)\n",
    "        \n",
    "    def init_hidden(self, batch_size): # RNNの隠れ層 hidden を初期化\n",
    "        hedden = torch.zeros(self.rnn_layers, batch_size, self.hidden_layer_size)\n",
    "        return hedden\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        x = x.view(batch_size, self.seq_len, self.feature_size)  # (Batch, Cannel, Height, Width) -> (Batch, Height, Width) = (Batch, Seqence, Feature)\n",
    "                                                                 # 画像の Height を時系列のSequenceに、Width を特徴量の次元としてRNNに入力する\n",
    "        x = x.permute(1, 0, 2)                                   # (Batch, Seqence, Feature) -> (Seqence , Batch, Feature)\n",
    "        \n",
    "        rnn_out, h_n = self.simple_rnn(x, self.hidden)           # RNNの入力データのShapeは(Seqence, Batch, Feature)\n",
    "                                                                 # (h_n) のShapeは (num_layers, batch, hidden_size)\n",
    "        x = h_n[-1,:,:]                                          # RNN_layersの最後のレイヤーを取り出す (l, B, h)-> (B, h)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデル作成\n",
    "net = Net().to(device)   # GPUを使用する場合のために明示的に .to(device) を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (simple_rnn): RNN(28, 128)\n",
      "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#ネットワークのレイヤー確認\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 損失関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.CrossEntropyLoss() はソフトマックス関数＋クロスエントロピー誤差\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化手法の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習・検証の実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, device, num_epochs):\n",
    "    \n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epochごとの学習と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "            else:\n",
    "                net.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "\n",
    "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for i , (inputs, labels) in tqdm(enumerate(dataloaders_dict[phase])):\n",
    "                \n",
    "                # GPUを使用する場合は明示的に指定\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):  # 訓練モードのみ勾配を算出\n",
    "                    outputs = net(inputs)              # 順伝播\n",
    "                    loss = criterion(outputs, labels)  # 損失を計算\n",
    "                    _, preds = torch.max(outputs, 1)   # ラベルを予測\n",
    "                    \n",
    "  \n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # イタレーション結果の計算\n",
    "                    # lossの合計を更新\n",
    "                    epoch_loss += loss.item() * inputs.size(0)  \n",
    "                    # 正解数の合計を更新\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # epochごとのlossと正解率を表示\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 59.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [00:04, 68.84it/s]\n",
      "4it [00:00, 34.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 2.3301 Acc: 0.0954\n",
      "Epoch 2/3\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:12, 50.79it/s]\n",
      "8it [00:00, 71.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9101 Acc: 0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [00:04, 72.83it/s]\n",
      "6it [00:00, 53.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5833 Acc: 0.8081\n",
      "Epoch 3/3\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "625it [00:12, 50.88it/s]\n",
      "7it [00:00, 67.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4456 Acc: 0.8674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [00:04, 69.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4203 Acc: 0.8796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 学習・検証を実行する\n",
    "num_epochs = 3\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストデータに対する予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_iterator = iter(dataloaders_dict[\"test\"])  # イテレータに変換\n",
    "imges, labels = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "\n",
    "net.eval() #推論モード\n",
    "with torch.set_grad_enabled(False):   # 推論モードでは勾配を算出しない\n",
    "    outputs = net(imges)               # 順伝播\n",
    "    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "    \n",
    "#テストデータの予測結果を描画\n",
    "plt.imshow(imges[0].numpy().reshape(28,28), cmap='gray')\n",
    "plt.title(\"Label: Target={}, Predict={}\".format(labels[0], preds[0].numpy()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
